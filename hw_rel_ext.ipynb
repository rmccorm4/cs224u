{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework and bake-off: Relation extraction using distant supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Bill MacCartney and Christopher Potts\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2020\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Overview](#Overview)\n",
    "1. [Set-up](#Set-up)\n",
    "1. [Baselines](#Baselines)\n",
    "  1. [Hand-build feature functions](#Hand-build-feature-functions)\n",
    "  1. [Distributed representations](#Distributed-representations)\n",
    "1. [Homework questions](#Homework-questions)\n",
    "  1. [Different model factory [1 points]](#Different-model-factory-[1-points])\n",
    "  1. [Directional unigram features [1.5 points]](#Directional-unigram-features-[1.5-points])\n",
    "  1. [The part-of-speech tags of the \"middle\" words [1.5 points]](#The-part-of-speech-tags-of-the-\"middle\"-words-[1.5-points])\n",
    "  1. [Bag of Synsets [2 points]](#Bag-of-Synsets-[2-points])\n",
    "  1. [Your original system [3 points]](#Your-original-system-[3-points])\n",
    "1. [Bake-off [1 point]](#Bake-off-[1-point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This homework and associated bake-off are devoted to developing really effective relation extraction systems using distant supervision. \n",
    "\n",
    "As with the previous assignments, this notebook first establishes a baseline system. The initial homework questions ask you to create additional baselines and suggest areas for innovation, and the final homework question asks you to develop an original system for you to enter into the bake-off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "\n",
    "See [the first notebook in this unit](rel_ext_01_task.ipynb#Set-up) for set-up instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import rel_ext\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we unite our corpus and KB into a dataset, and create some splits for experimentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_ext_data_home = os.path.join('data', 'rel_ext_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = rel_ext.Corpus(os.path.join(rel_ext_data_home, 'corpus.tsv.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = rel_ext.KB(os.path.join(rel_ext_data_home, 'kb.tsv.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rel_ext.Dataset(corpus, kb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are not wedded to this set-up for splits. The bake-off will be conducted on a previously unseen test-set, so all of the data in `dataset` is fair game:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = dataset.build_splits(\n",
    "    split_names=['tiny', 'train', 'dev'],\n",
    "    split_fracs=[0.01, 0.79, 0.20],\n",
    "    seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tiny': Corpus with 3,474 examples; KB with 445 triples,\n",
       " 'train': Corpus with 263,285 examples; KB with 36,191 triples,\n",
       " 'dev': Corpus with 64,937 examples; KB with 9,248 triples,\n",
       " 'all': Corpus with 331,696 examples; KB with 45,884 triples}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hand-build feature functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_bag_of_words_featurizer(kbt, corpus, feature_counter):\n",
    "    for ex in corpus.get_examples_for_entities(kbt.sbj, kbt.obj):\n",
    "        for word in ex.middle.split(' '):\n",
    "            feature_counter[word] += 1\n",
    "    for ex in corpus.get_examples_for_entities(kbt.obj, kbt.sbj):\n",
    "        for word in ex.middle.split(' '):\n",
    "            feature_counter[word] += 1\n",
    "    return feature_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizers = [simple_bag_of_words_featurizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_factory = lambda: LogisticRegression(fit_intercept=True, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.868      0.385      0.694        340       5716\n",
      "author                    0.751      0.546      0.699        509       5885\n",
      "capital                   0.690      0.211      0.474         95       5471\n",
      "contains                  0.799      0.602      0.750       3904       9280\n",
      "film_performance          0.767      0.559      0.714        766       6142\n",
      "founders                  0.795      0.397      0.662        380       5756\n",
      "genre                     0.571      0.141      0.355        170       5546\n",
      "has_sibling               0.868      0.236      0.566        499       5875\n",
      "has_spouse                0.891      0.332      0.666        594       5970\n",
      "is_a                      0.685      0.223      0.485        497       5873\n",
      "nationality               0.632      0.183      0.424        301       5677\n",
      "parents                   0.895      0.545      0.793        312       5688\n",
      "place_of_birth            0.645      0.210      0.456        233       5609\n",
      "place_of_death            0.471      0.101      0.271        159       5535\n",
      "profession                0.618      0.190      0.426        247       5623\n",
      "worked_at                 0.667      0.240      0.492        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.726      0.319      0.558       9248      95264\n"
     ]
    }
   ],
   "source": [
    "baseline_results = rel_ext.experiment(\n",
    "    splits,\n",
    "    train_split='train',\n",
    "    test_split='dev',\n",
    "    featurizers=featurizers,\n",
    "    model_factory=model_factory,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Studying model weights might yield insights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest and lowest feature weights for relation adjoins:\n",
      "\n",
      "     2.538 CÃ³rdoba\n",
      "     2.457 Taluks\n",
      "     2.318 Valais\n",
      "     ..... .....\n",
      "    -1.475 who\n",
      "    -1.547 he\n",
      "    -2.346 Earth\n",
      "\n",
      "Highest and lowest feature weights for relation author:\n",
      "\n",
      "     2.620 author\n",
      "     2.335 wrote\n",
      "     2.332 by\n",
      "     ..... .....\n",
      "    -3.005 controversial\n",
      "    -3.584 1945\n",
      "    -3.723 17th\n",
      "\n",
      "Highest and lowest feature weights for relation capital:\n",
      "\n",
      "     3.471 capital\n",
      "     1.779 km\n",
      "     1.777 posted\n",
      "     ..... .....\n",
      "    -1.221 largest\n",
      "    -1.242 and\n",
      "    -1.294 Westminster\n",
      "\n",
      "Highest and lowest feature weights for relation contains:\n",
      "\n",
      "     2.787 third-largest\n",
      "     2.428 bordered\n",
      "     2.148 attended\n",
      "     ..... .....\n",
      "    -2.461 Henley-on-Thames\n",
      "    -3.885 Ceylon\n",
      "    -6.027 Bronx\n",
      "\n",
      "Highest and lowest feature weights for relation film_performance:\n",
      "\n",
      "     3.847 starring\n",
      "     3.633 co-starring\n",
      "     3.586 alongside\n",
      "     ..... .....\n",
      "    -1.850 Malice\n",
      "    -2.000 Westminster\n",
      "    -2.272 spy\n",
      "\n",
      "Highest and lowest feature weights for relation founders:\n",
      "\n",
      "     3.833 founded\n",
      "     3.715 founder\n",
      "     2.920 company\n",
      "     ..... .....\n",
      "    -1.970 William\n",
      "    -2.015 Griffith\n",
      "    -2.020 band\n",
      "\n",
      "Highest and lowest feature weights for relation genre:\n",
      "\n",
      "     2.917 series\n",
      "     2.817 movie\n",
      "     2.661 \n",
      "     ..... .....\n",
      "    -1.066 ;\n",
      "    -1.408 and\n",
      "    -1.960 at\n",
      "\n",
      "Highest and lowest feature weights for relation has_sibling:\n",
      "\n",
      "     5.390 brother\n",
      "     3.869 sister\n",
      "     2.882 nephew\n",
      "     ..... .....\n",
      "    -1.359 His\n",
      "    -1.366 he\n",
      "    -1.838 Her\n",
      "\n",
      "Highest and lowest feature weights for relation has_spouse:\n",
      "\n",
      "     5.304 wife\n",
      "     4.425 widow\n",
      "     4.182 husband\n",
      "     ..... .....\n",
      "    -1.307 including\n",
      "    -1.308 which\n",
      "    -1.357 on\n",
      "\n",
      "Highest and lowest feature weights for relation is_a:\n",
      "\n",
      "     3.174 \n",
      "     2.926 family\n",
      "     2.579 Genus\n",
      "     ..... .....\n",
      "    -1.495 at\n",
      "    -1.632 now\n",
      "    -1.675 York\n",
      "\n",
      "Highest and lowest feature weights for relation nationality:\n",
      "\n",
      "     2.873 born\n",
      "     1.882 Pinky\n",
      "     1.861 caliph\n",
      "     ..... .....\n",
      "    -1.498 foreign\n",
      "    -1.620 American\n",
      "    -1.977 1961\n",
      "\n",
      "Highest and lowest feature weights for relation parents:\n",
      "\n",
      "     5.097 son\n",
      "     4.450 daughter\n",
      "     4.417 father\n",
      "     ..... .....\n",
      "    -1.526 no\n",
      "    -1.601 filmmaker\n",
      "    -2.371 played\n",
      "\n",
      "Highest and lowest feature weights for relation place_of_birth:\n",
      "\n",
      "     3.981 born\n",
      "     2.912 mayor\n",
      "     2.726 birthplace\n",
      "     ..... .....\n",
      "    -1.446 or\n",
      "    -1.515 American\n",
      "    -1.715 Westminster\n",
      "\n",
      "Highest and lowest feature weights for relation place_of_death:\n",
      "\n",
      "     2.579 died\n",
      "     2.013 Emperor\n",
      "     1.914 rebuilt\n",
      "     ..... .....\n",
      "    -1.176 or\n",
      "    -1.253 and\n",
      "    -1.977 Westminster\n",
      "\n",
      "Highest and lowest feature weights for relation profession:\n",
      "\n",
      "     3.714 \n",
      "     2.685 American\n",
      "     2.393 British\n",
      "     ..... .....\n",
      "    -1.297 are\n",
      "    -1.667 York\n",
      "    -2.103 on\n",
      "\n",
      "Highest and lowest feature weights for relation worked_at:\n",
      "\n",
      "     3.258 professor\n",
      "     2.957 CEO\n",
      "     2.912 president\n",
      "     ..... .....\n",
      "    -1.273 William\n",
      "    -1.479 war\n",
      "    -1.795 or\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rel_ext.examine_model_weights(baseline_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed representations\n",
    "\n",
    "This simple baseline sums the GloVe vector representations for all of the words in the \"middle\" span and feeds those representations into the standard `LogisticRegression`-based `model_factory`. The crucial parameter that enables this is `vectorize=False`. This essentially says to `rel_ext.experiment` that your featurizer or your model will do the work of turning examples into vectors; in that case, `rel_ext.experiment` just organizes these representations by relation type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_HOME = os.path.join('data', 'glove.6B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_lookup = utils.glove2dict(\n",
    "    os.path.join(GLOVE_HOME, 'glove.6B.300d.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_middle_featurizer(kbt, corpus, np_func=np.sum):\n",
    "    reps = []\n",
    "    for ex in corpus.get_examples_for_entities(kbt.sbj, kbt.obj):\n",
    "        for word in ex.middle.split():\n",
    "            rep = glove_lookup.get(word)\n",
    "            if rep is not None:\n",
    "                reps.append(rep)\n",
    "    # A random representation of the right dimensionality if the\n",
    "    # example happens not to overlap with GloVe's vocabulary:\n",
    "    if len(reps) == 0:\n",
    "        dim = len(next(iter(glove_lookup.values())))                \n",
    "        return utils.randvec(n=dim)\n",
    "    else:\n",
    "        return np_func(reps, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.853      0.462      0.730        340       5716\n",
      "author                    0.824      0.442      0.703        509       5885\n",
      "capital                   0.633      0.200      0.442         95       5471\n",
      "contains                  0.664      0.416      0.593       3904       9280\n",
      "film_performance          0.825      0.315      0.623        766       6142\n",
      "founders                  0.733      0.232      0.512        380       5756\n",
      "genre                     0.455      0.059      0.194        170       5546\n",
      "has_sibling               0.826      0.246      0.562        499       5875\n",
      "has_spouse                0.883      0.355      0.681        594       5970\n",
      "is_a                      0.722      0.141      0.395        497       5873\n",
      "nationality               0.695      0.219      0.485        301       5677\n",
      "parents                   0.860      0.413      0.707        312       5688\n",
      "place_of_birth            0.628      0.210      0.450        233       5609\n",
      "place_of_death            0.529      0.113      0.305        159       5535\n",
      "profession                0.614      0.142      0.368        247       5623\n",
      "worked_at                 0.691      0.269      0.526        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.715      0.265      0.517       9248      95264\n"
     ]
    }
   ],
   "source": [
    "glove_results = rel_ext.experiment(\n",
    "    splits,\n",
    "    train_split='train',\n",
    "    test_split='dev',\n",
    "    featurizers=[glove_middle_featurizer],    \n",
    "    vectorize=False, # Crucial for this featurizer!\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same basic code design, one can also use the PyTorch models included in the course repo, or write new ones that are better aligned with the task. For those models, it's likely that the featurizer will just return a list of tokens (or perhaps a list of lists of tokens), and the model will map those into vectors using an embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework questions\n",
    "\n",
    "Please embed your homework responses in this notebook, and do not delete any cells from the notebook. (You are free to add as many cells as you like as part of your responses.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different model factory [1 points]\n",
    "\n",
    "The code in `rel_ext` makes it very easy to experiment with other classifier models: one need only redefine the `model_factory` argument. This question asks you to assess a [Support Vector Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).\n",
    "\n",
    "__To submit:__ A wrapper function `run_svm_model_factory` that does the following: \n",
    "\n",
    "1. Uses `rel_ext.experiment` with the model factory set to one based in an `SVC` with `kernel='linear'` and all other arguments left with default values. \n",
    "1. Trains on the 'train' part of `splits`.\n",
    "1. Assesses on the `dev` part of `splits`.\n",
    "1. Uses `featurizers` as defined above. \n",
    "1. Returns the return value of `rel_ext.experiment` for this set-up.\n",
    "\n",
    "The function `test_run_svm_model_factory` will check that your function conforms to these general specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm_model_factory():\n",
    "    \n",
    "    ##### YOUR CODE HERE\n",
    "    from sklearn.svm import SVC\n",
    "    svm_results = rel_ext.experiment(\n",
    "        splits,\n",
    "        train_split='train',\n",
    "        test_split='dev',\n",
    "        featurizers=featurizers,\n",
    "        model_factory=lambda: SVC(kernel=\"linear\"),\n",
    "        verbose=True\n",
    "    )\n",
    "    return svm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run_svm_model_factory(run_svm_model_factory):\n",
    "    results = run_svm_model_factory()\n",
    "    assert 'featurizers' in results, \\\n",
    "        \"The return value of `run_svm_model_factory` seems not to be correct\"\n",
    "    # Check one of the models to make sure it's an SVC:\n",
    "    assert 'SVC' in results['models']['adjoins'].__class__.__name__, \\\n",
    "        \"It looks like the model factor wasn't set to use an SVC.\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.823      0.341      0.642        340       5716\n",
      "author                    0.705      0.595      0.680        509       5885\n",
      "capital                   0.636      0.295      0.517         95       5471\n",
      "contains                  0.778      0.608      0.736       3904       9280\n",
      "film_performance          0.715      0.614      0.692        766       6142\n",
      "founders                  0.735      0.461      0.657        380       5756\n",
      "genre                     0.639      0.229      0.471        170       5546\n",
      "has_sibling               0.819      0.244      0.557        499       5875\n",
      "has_spouse                0.846      0.350      0.659        594       5970\n",
      "is_a                      0.577      0.272      0.471        497       5873\n",
      "nationality               0.543      0.189      0.395        301       5677\n",
      "parents                   0.838      0.580      0.770        312       5688\n",
      "place_of_birth            0.578      0.223      0.438        233       5609\n",
      "place_of_death            0.447      0.107      0.273        159       5535\n",
      "profession                0.549      0.227      0.427        247       5623\n",
      "worked_at                 0.563      0.277      0.467        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.674      0.351      0.553       9248      95264\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    test_run_svm_model_factory(run_svm_model_factory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directional unigram features [1.5 points]\n",
    "\n",
    "The current bag-of-words representation makes no distinction between \"forward\" and \"reverse\" examples. But, intuitively, there is big difference between _X and his son Y_ and _Y and his son X_. This question asks you to modify `simple_bag_of_words_featurizer` to capture these differences. \n",
    "\n",
    "__To submit:__\n",
    "\n",
    "1. A feature function `directional_bag_of_words_featurizer` that is just like `simple_bag_of_words_featurizer` except that it distinguishes \"forward\" and \"reverse\". To do this, you just need to mark each word feature for whether it is derived from a subjectâobject example or from an objectâsubject example.  The included function `test_directional_bag_of_words_featurizer` should help verify that you've done this correctly.\n",
    "\n",
    "2. A call to `rel_ext.experiment` with `directional_bag_of_words_featurizer` as the only featurizer. (Aside from this, use all the default values for `rel_ext.experiment` as exemplified above in this notebook.)\n",
    "\n",
    "3. `rel_ext.experiment` returns some of the core objects used in the experiment. How many feature names does the `vectorizer` have for the experiment run in the previous step? Include the code needed for getting this value. (Note: we're partly asking you to figure out how to get this value by using the sklearn documentation, so please don't ask how to do it!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.865      0.397      0.700        340       5716\n",
      "author                    0.855      0.589      0.784        509       5885\n",
      "capital                   0.605      0.274      0.487         95       5471\n",
      "contains                  0.819      0.686      0.789       3904       9280\n",
      "film_performance          0.839      0.661      0.796        766       6142\n",
      "founders                  0.831      0.400      0.683        380       5756\n",
      "genre                     0.782      0.253      0.551        170       5546\n",
      "has_sibling               0.828      0.251      0.567        499       5875\n",
      "has_spouse                0.857      0.354      0.667        594       5970\n",
      "is_a                      0.812      0.270      0.579        497       5873\n",
      "nationality               0.673      0.219      0.476        301       5677\n",
      "parents                   0.853      0.519      0.756        312       5688\n",
      "place_of_birth            0.718      0.240      0.514        233       5609\n",
      "place_of_death            0.639      0.145      0.380        159       5535\n",
      "profession                0.761      0.271      0.559        247       5623\n",
      "worked_at                 0.710      0.273      0.537        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.778      0.363      0.614       9248      95264\n"
     ]
    }
   ],
   "source": [
    "def directional_bag_of_words_featurizer(kbt, corpus, feature_counter): \n",
    "    # Append these to the end of the keys you add/access in \n",
    "    # `feature_counter` to distinguish the two orders. You'll\n",
    "    # need to use exactly these strings in order to pass \n",
    "    # `test_directional_bag_of_words_featurizer`.\n",
    "    subject_object_suffix = \"_SO\"\n",
    "    object_subject_suffix = \"_OS\"\n",
    "    \n",
    "    ##### YOUR CODE HERE\n",
    "    for ex in corpus.get_examples_for_entities(kbt.sbj, kbt.obj):\n",
    "        for word in ex.middle.split(' '):\n",
    "            feature_counter[word + subject_object_suffix] += 1\n",
    "    for ex in corpus.get_examples_for_entities(kbt.obj, kbt.sbj):\n",
    "        for word in ex.middle.split(' '):\n",
    "            feature_counter[word + object_subject_suffix] += 1\n",
    "\n",
    "    return feature_counter\n",
    "\n",
    "\n",
    "# Call to `rel_ext.experiment`:\n",
    "##### YOUR CODE HERE    \n",
    "directional_results = rel_ext.experiment(\n",
    "    splits,\n",
    "    train_split='train',\n",
    "    test_split='dev',\n",
    "    featurizers=[directional_bag_of_words_featurizer],\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_directional_bag_of_words_featurizer(corpus):\n",
    "    from collections import defaultdict\n",
    "    kbt = rel_ext.KBTriple(rel='worked_at', sbj='Randall_Munroe', obj='xkcd')\n",
    "    feature_counter = defaultdict(int)\n",
    "    # Make sure `feature_counter` is being updated, not reinitialized:\n",
    "    feature_counter['is_OS'] += 5\n",
    "    feature_counter = directional_bag_of_words_featurizer(kbt, corpus, feature_counter)\n",
    "    expected = defaultdict(\n",
    "        int, {'is_OS':6,'a_OS':1,'webcomic_OS':1,'created_OS':1,'by_OS':1})\n",
    "    assert feature_counter == expected, \\\n",
    "        \"Expected:\\n{}\\nGot:\\n{}\".format(expected, feature_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    test_directional_bag_of_words_featurizer(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The part-of-speech tags of the \"middle\" words [1.5 points]\n",
    "\n",
    "Our corpus distribution contains part-of-speech (POS) tagged versions of the core text spans. Let's begin to explore whether there is information in these sequences, focusing on `middle_POS`.\n",
    "\n",
    "__To submit:__\n",
    "\n",
    "1. A feature function `middle_bigram_pos_tag_featurizer` that is just like `simple_bag_of_words_featurizer` except that it creates a feature for bigram POS sequences. For example, given \n",
    "\n",
    "  `The/DT dog/N napped/V`\n",
    "  \n",
    "   we obtain the list of bigram POS sequences\n",
    "  \n",
    "   `b = ['<s> DT', 'DT N', 'N V', 'V </s>']`. \n",
    "   \n",
    "   Of course, `middle_bigram_pos_tag_featurizer` should return count dictionaries defined in terms of such bigram POS lists, on the model of `simple_bag_of_words_featurizer`.  Don't forget the start and end tags, to model those environments properly! The included function `test_middle_bigram_pos_tag_featurizer` should help verify that you've done this correctly.\n",
    "\n",
    "2. A call to `rel_ext.experiment` with `middle_bigram_pos_tag_featurizer` as the only featurizer. (Aside from this, use all the default values for `rel_ext.experiment` as exemplified above in this notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.841      0.341      0.650        340       5716\n",
      "author                    0.671      0.332      0.557        509       5885\n",
      "capital                   0.282      0.116      0.219         95       5471\n",
      "contains                  0.756      0.588      0.715       3904       9280\n",
      "film_performance          0.726      0.446      0.645        766       6142\n",
      "founders                  0.525      0.166      0.366        380       5756\n",
      "genre                     0.574      0.182      0.402        170       5546\n",
      "has_sibling               0.646      0.168      0.412        499       5875\n",
      "has_spouse                0.720      0.273      0.542        594       5970\n",
      "is_a                      0.573      0.165      0.384        497       5873\n",
      "nationality               0.393      0.073      0.210        301       5677\n",
      "parents                   0.592      0.279      0.483        312       5688\n",
      "place_of_birth            0.591      0.167      0.392        233       5609\n",
      "place_of_death            0.400      0.088      0.234        159       5535\n",
      "profession                0.603      0.178      0.408        247       5623\n",
      "worked_at                 0.446      0.120      0.289        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.584      0.230      0.432       9248      95264\n"
     ]
    }
   ],
   "source": [
    "def middle_bigram_pos_tag_featurizer(kbt, corpus, feature_counter):\n",
    "    \n",
    "    ##### YOUR CODE HERE\n",
    "    for ex in corpus.get_examples_for_entities(kbt.sbj, kbt.obj):\n",
    "        for tag_bigram in get_tag_bigrams(ex.middle_POS):\n",
    "            feature_counter[tag_bigram] += 1\n",
    "        \n",
    "    for ex in corpus.get_examples_for_entities(kbt.obj, kbt.sbj):\n",
    "        for tag_bigram in get_tag_bigrams(ex.middle_POS):\n",
    "            feature_counter[tag_bigram] += 1\n",
    "            \n",
    "    return feature_counter\n",
    "\n",
    "\n",
    "def get_tag_bigrams(s):\n",
    "    \"\"\"Suggested helper method for `middle_bigram_pos_tag_featurizer`.\n",
    "    This should be defined so that it returns a list of str, where each \n",
    "    element is a POS bigram.\"\"\"\n",
    "    # The values of `start_symbol` and `end_symbol` are defined\n",
    "    # here so that you can use `test_middle_bigram_pos_tag_featurizer`.\n",
    "    start_symbol = \"<s>\"\n",
    "    end_symbol = \"</s>\"\n",
    "    \n",
    "    ##### YOUR CODE HERE\n",
    "    tags = get_tags(s)\n",
    "    tags.insert(0, start_symbol)\n",
    "    tags.append(end_symbol)\n",
    "    return [\" \".join(tags[i:i+2]) for i in range(len(tags)-1)]\n",
    "    \n",
    "\n",
    "def get_tags(s): \n",
    "    \"\"\"Given a sequence of word/POS elements (lemmas), this function\n",
    "    returns a list containing just the POS elements, in order.    \n",
    "    \"\"\"\n",
    "    return [parse_lem(lem)[1] for lem in s.strip().split(' ') if lem]\n",
    "\n",
    "\n",
    "def parse_lem(lem):\n",
    "    \"\"\"Helper method for parsing word/POS elements. It just splits\n",
    "    on the rightmost / and returns (word, POS) as a tuple of str.\"\"\"\n",
    "    return lem.strip().rsplit('/', 1)  \n",
    "\n",
    "# Call to `rel_ext.experiment`:\n",
    "##### YOUR CODE HERE\n",
    "bigram_pos_tag_results = rel_ext.experiment(\n",
    "    splits,\n",
    "    train_split='train',\n",
    "    test_split='dev',\n",
    "    featurizers=[middle_bigram_pos_tag_featurizer],\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_middle_bigram_pos_tag_featurizer(corpus):\n",
    "    from collections import defaultdict\n",
    "    kbt = rel_ext.KBTriple(rel='worked_at', sbj='Randall_Munroe', obj='xkcd')\n",
    "    feature_counter = defaultdict(int)\n",
    "    # Make sure `feature_counter` is being updated, not reinitialized:\n",
    "    feature_counter['<s> VBZ'] += 5\n",
    "    feature_counter = middle_bigram_pos_tag_featurizer(kbt, corpus, feature_counter)\n",
    "    expected = defaultdict(\n",
    "        int, {'<s> VBZ':6,'VBZ DT':1,'DT JJ':1,'JJ VBN':1,'VBN IN':1,'IN </s>':1})\n",
    "    assert feature_counter == expected, \\\n",
    "        \"Expected:\\n{}\\nGot:\\n{}\".format(expected, feature_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    test_middle_bigram_pos_tag_featurizer(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Synsets [2 points]\n",
    "\n",
    "The following allows you to use NLTK's WordNet API to get the synsets compatible with _dog_ as used as a noun:\n",
    "\n",
    "```\n",
    "from nltk.corpus import wordnet as wn\n",
    "dog = wn.synsets('dog', pos='n')\n",
    "dog\n",
    "[Synset('dog.n.01'),\n",
    " Synset('frump.n.01'),\n",
    " Synset('dog.n.03'),\n",
    " Synset('cad.n.01'),\n",
    " Synset('frank.n.02'),\n",
    " Synset('pawl.n.01'),\n",
    " Synset('andiron.n.01')]\n",
    "```\n",
    "\n",
    "This question asks you to create synset-based features from the word/tag pairs in `middle_POS`.\n",
    "\n",
    "__To submit:__\n",
    "\n",
    "1. A feature function `synset_featurizer` that is just like `simple_bag_of_words_featurizer` except that it returns a list of synsets derived from `middle_POS`. Stringify these objects with `str` so that they can be `dict` keys. Use `convert_tag` (included below) to convert tags to `pos` arguments usable by `wn.synsets`. The included function `test_synset_featurizer` should help verify that you've done this correctly.\n",
    "\n",
    "2. A call to `rel_ext.experiment` with `synset_featurizer` as the only featurizer. (Aside from this, use all the default values for `rel_ext.experiment`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    import nltk\n",
    "    nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-32286e32c6bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mtest_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dev'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mfeaturizers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msynset_featurizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     verbose=True)\n\u001b[0m",
      "\u001b[0;32m/mnt/rel_ext.py\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(splits, featurizers, train_split, test_split, model_factory, train_sampling_rate, test_sampling_rate, vectorize, verbose)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0msampling_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sampling_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mvectorize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         verbose=verbose)\n\u001b[0m\u001b[1;32m    547\u001b[0m     predictions, test_y = predict(\n\u001b[1;32m    548\u001b[0m         \u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/rel_ext.py\u001b[0m in \u001b[0;36mtrain_models\u001b[0;34m(splits, featurizers, split_name, model_factory, sampling_rate, vectorize, verbose)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0mtrain_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     train_X, vectorizer = train_dataset.featurize(\n\u001b[0;32m--> 484\u001b[0;31m         train_o, featurizers, vectorize=vectorize)\n\u001b[0m\u001b[1;32m    485\u001b[0m     \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_relations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/rel_ext.py\u001b[0m in \u001b[0;36mfeaturize\u001b[0;34m(self, kbts_by_rel, featurizers, vectorizer, vectorize)\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mfeaturizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeaturizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeaturizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkbt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0mfeat_counters_by_rel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mfeat_matrices_by_rel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-32286e32c6bf>\u001b[0m in \u001b[0;36msynset_featurizer\u001b[0;34m(kbt, corpus, feature_counter)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m##### YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_examples_for_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msbj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msynset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_synsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmiddle_POS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mfeature_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-32286e32c6bf>\u001b[0m in \u001b[0;36mget_synsets\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0msynsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0msynset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0msynsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def synset_featurizer(kbt, corpus, feature_counter):\n",
    "    \n",
    "    ##### YOUR CODE HERE\n",
    "    for ex in corpus.get_examples_for_entities(kbt.sbj, kbt.obj):\n",
    "        for synset in get_synsets(ex.middle_POS):\n",
    "            feature_counter[synset] += 1\n",
    "        \n",
    "    for ex in corpus.get_examples_for_entities(kbt.obj, kbt.sbj):\n",
    "        for synset in get_synsets(ex.middle_POS):\n",
    "            feature_counter[synset] += 1\n",
    "            \n",
    "    return feature_counter\n",
    "\n",
    "\n",
    "def get_synsets(s):\n",
    "    \"\"\"Suggested helper method for `synset_featurizer`. This should\n",
    "    be completed so that it returns a list of stringified Synsets \n",
    "    associated with elements of `s`.\n",
    "    \"\"\"   \n",
    "    # Use `parse_lem` from the previous question to get a list of\n",
    "    # (word, POS) pairs. Remember to convert the POS strings.\n",
    "    wt = [parse_lem(lem) for lem in s.strip().split(' ') if lem]\n",
    "    \n",
    "    ##### YOUR CODE HERE\n",
    "    synsets = []\n",
    "    for word, tag in wt:\n",
    "        synset = [str(s) for s in wn.synsets(word, pos=convert_tag(tag))]\n",
    "        synsets.extend(synset)\n",
    "\n",
    "    return synsets\n",
    "    \n",
    "    \n",
    "def convert_tag(t):\n",
    "    \"\"\"Converts tags so that they can be used by WordNet:\n",
    "    \n",
    "    | Tag begins with | WordNet tag |\n",
    "    |-----------------|-------------|\n",
    "    | `N`             | `n`         |\n",
    "    | `V`             | `v`         |\n",
    "    | `J`             | `a`         |\n",
    "    | `R`             | `r`         |\n",
    "    | Otherwise       | `None`      |\n",
    "    \"\"\"        \n",
    "    if t[0].lower() in {'n', 'v', 'r'}:\n",
    "        return t[0].lower()\n",
    "    elif t[0].lower() == 'j':\n",
    "        return 'a'\n",
    "    else:\n",
    "        return None    \n",
    "\n",
    "\n",
    "# Call to `rel_ext.experiment`:\n",
    "##### YOUR CODE HERE    \n",
    "synset_results = rel_ext.experiment(\n",
    "    splits,\n",
    "    train_split='train',\n",
    "    test_split='dev',\n",
    "    featurizers=[synset_featurizer],\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_synset_featurizer(corpus):\n",
    "    from collections import defaultdict\n",
    "    kbt = rel_ext.KBTriple(rel='worked_at', sbj='Randall_Munroe', obj='xkcd')\n",
    "    feature_counter = defaultdict(int)\n",
    "    # Make sure `feature_counter` is being updated, not reinitialized:\n",
    "    feature_counter[\"Synset('be.v.01')\"] += 5\n",
    "    feature_counter = synset_featurizer(kbt, corpus, feature_counter)\n",
    "    # The full return values for this tend to be long, so we just\n",
    "    # test a few examples to avoid cluttering up this notebook.\n",
    "    test_cases = {\n",
    "        \"Synset('be.v.01')\": 6,\n",
    "        \"Synset('embody.v.02')\": 1\n",
    "    }\n",
    "    for ss, expected in test_cases.items():   \n",
    "        result = feature_counter[ss]\n",
    "        assert result == expected, \\\n",
    "            \"Incorrect count for {}: Expected {}; Got {}\".format(ss, expected, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    test_synset_featurizer(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your original system [3 points]\n",
    "\n",
    "There are many options, and this could easily grow into a project. Here are a few ideas:\n",
    "\n",
    "- Try out different classifier models, from `sklearn` and elsewhere.\n",
    "- Add a feature that indicates the length of the middle.\n",
    "- Augment the bag-of-words representation to include bigrams or trigrams (not just unigrams).\n",
    "- Introduce features based on the entity mentions themselves. <!-- \\[SPOILER: it helps a lot, maybe 4% in F-score. And combines nicely with the directional features.\\] -->\n",
    "- Experiment with features based on the context outside (rather than between) the two entity mentions âÂ that is, the words before the first mention, or after the second.\n",
    "- Try adding features which capture syntactic information, such as the dependency-path features used by Mintz et al. 2009. The [NLTK](https://www.nltk.org/) toolkit contains a variety of [parsing algorithms](http://www.nltk.org/api/nltk.parse.html) that may help.\n",
    "- The bag-of-words representation does not permit generalization across word categories such as names of people, places, or companies. Can we do better using word embeddings such as [GloVe](https://nlp.stanford.edu/projects/glove/)?\n",
    "\n",
    "In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directional Bag of Words + Other Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.811      0.391      0.668        340       5716\n",
      "author                    0.803      0.672      0.773        509       5885\n",
      "capital                   0.650      0.274      0.510         95       5471\n",
      "contains                  0.794      0.675      0.767       3904       9280\n",
      "film_performance          0.781      0.698      0.763        766       6142\n",
      "founders                  0.761      0.461      0.673        380       5756\n",
      "genre                     0.605      0.441      0.563        170       5546\n",
      "has_sibling               0.786      0.251      0.551        499       5875\n",
      "has_spouse                0.851      0.355      0.665        594       5970\n",
      "is_a                      0.657      0.308      0.535        497       5873\n",
      "nationality               0.571      0.266      0.465        301       5677\n",
      "parents                   0.808      0.593      0.753        312       5688\n",
      "place_of_birth            0.594      0.245      0.462        233       5609\n",
      "place_of_death            0.380      0.119      0.265        159       5535\n",
      "profession                0.711      0.328      0.576        247       5623\n",
      "worked_at                 0.653      0.318      0.539        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.701      0.400      0.595       9248      95264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    directional_svm_linear_results = rel_ext.experiment(\n",
    "        splits,\n",
    "        train_split='train',\n",
    "        test_split='dev',\n",
    "        featurizers=[directional_bag_of_words_featurizer],\n",
    "        model_factory=lambda: SVC(kernel=\"linear\"),\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.844      0.350      0.658        340       5716\n",
      "author                    0.833      0.578      0.765        509       5885\n",
      "capital                   0.800      0.084      0.296         95       5471\n",
      "contains                  0.852      0.569      0.774       3904       9280\n",
      "film_performance          0.857      0.580      0.782        766       6142\n",
      "founders                  0.886      0.287      0.625        380       5756\n",
      "genre                     0.727      0.094      0.310        170       5546\n",
      "has_sibling               0.879      0.188      0.507        499       5875\n",
      "has_spouse                0.868      0.276      0.607        594       5970\n",
      "is_a                      0.830      0.187      0.492        497       5873\n",
      "nationality               0.760      0.126      0.379        301       5677\n",
      "parents                   0.857      0.500      0.750        312       5688\n",
      "place_of_birth            0.851      0.172      0.475        233       5609\n",
      "place_of_death            0.000      0.000      0.000        159       5535\n",
      "profession                0.844      0.219      0.537        247       5623\n",
      "worked_at                 0.837      0.149      0.435        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.783      0.272      0.525       9248      95264\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    directional_svm_rbf_results = rel_ext.experiment(\n",
    "        splits,\n",
    "        train_split='train',\n",
    "        test_split='dev',\n",
    "        featurizers=[directional_bag_of_words_featurizer],\n",
    "        model_factory=lambda: SVC(kernel=\"rbf\"),\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-grams featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def middle_ngram_pos_tag_featurizer(kbt, corpus, feature_counter, n=2):\n",
    "    \n",
    "    ##### YOUR CODE HERE\n",
    "    for ex in corpus.get_examples_for_entities(kbt.sbj, kbt.obj):\n",
    "        for tag_bigram in get_tag_ngrams(ex.middle_POS, n=n):\n",
    "            feature_counter[tag_bigram] += 1\n",
    "        \n",
    "    for ex in corpus.get_examples_for_entities(kbt.obj, kbt.sbj):\n",
    "        for tag_bigram in get_tag_ngrams(ex.middle_POS, n=n):\n",
    "            feature_counter[tag_bigram] += 1\n",
    "            \n",
    "    return feature_counter\n",
    "\n",
    "\n",
    "def get_tag_ngrams(s, n=2):\n",
    "    \"\"\"Suggested helper method for `middle_bigram_pos_tag_featurizer`.\n",
    "    This should be defined so that it returns a list of str, where each \n",
    "    element is a POS bigram.\"\"\"\n",
    "    # The values of `start_symbol` and `end_symbol` are defined\n",
    "    # here so that you can use `test_middle_bigram_pos_tag_featurizer`.\n",
    "    start_symbol = \"<s>\"\n",
    "    end_symbol = \"</s>\"\n",
    "    \n",
    "    ##### YOUR CODE HERE\n",
    "    tags = get_tags(s)\n",
    "    tags.insert(0, start_symbol)\n",
    "    tags.append(end_symbol)\n",
    "    return [\" \".join(tags[i:i+n]) for i in range(len(tags)-1)]\n",
    "    \n",
    "\n",
    "def get_tags(s): \n",
    "    \"\"\"Given a sequence of word/POS elements (lemmas), this function\n",
    "    returns a list containing just the POS elements, in order.    \n",
    "    \"\"\"\n",
    "    return [parse_lem(lem)[1] for lem in s.strip().split(' ') if lem]\n",
    "\n",
    "\n",
    "def parse_lem(lem):\n",
    "    \"\"\"Helper method for parsing word/POS elements. It just splits\n",
    "    on the rightmost / and returns (word, POS) as a tuple of str.\"\"\"\n",
    "    return lem.strip().rsplit('/', 1)  \n",
    "\n",
    "\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    from functools import partial\n",
    "    middle_3gram_pos_tag_featurizer = partial(middle_ngram_pos_tag_featurizer, n=3)\n",
    "    middle_4gram_pos_tag_featurizer = partial(middle_ngram_pos_tag_featurizer, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.717      0.335      0.584        340       5716\n",
      "author                    0.655      0.358      0.561        509       5885\n",
      "capital                   0.387      0.126      0.274         95       5471\n",
      "contains                  0.763      0.592      0.721       3904       9280\n",
      "film_performance          0.677      0.507      0.634        766       6142\n",
      "founders                  0.521      0.226      0.413        380       5756\n",
      "genre                     0.405      0.176      0.322        170       5546\n",
      "has_sibling               0.595      0.138      0.358        499       5875\n",
      "has_spouse                0.665      0.254      0.503        594       5970\n",
      "is_a                      0.502      0.231      0.407        497       5873\n",
      "nationality               0.287      0.083      0.193        301       5677\n",
      "parents                   0.627      0.458      0.584        312       5688\n",
      "place_of_birth            0.465      0.197      0.366        233       5609\n",
      "place_of_death            0.160      0.050      0.111        159       5535\n",
      "profession                0.598      0.235      0.457        247       5623\n",
      "worked_at                 0.414      0.149      0.305        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.527      0.257      0.425       9248      95264\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    threegram_pos_tag_results = rel_ext.experiment(\n",
    "        splits,\n",
    "        train_split='train',\n",
    "        test_split='dev',\n",
    "        featurizers=[middle_3gram_pos_tag_featurizer],\n",
    "        model_factory=lambda: SVC(kernel=\"linear\"),\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.719      0.338      0.587        340       5716\n",
      "author                    0.620      0.346      0.535        509       5885\n",
      "capital                   0.450      0.095      0.257         95       5471\n",
      "contains                  0.745      0.590      0.708       3904       9280\n",
      "film_performance          0.694      0.526      0.652        766       6142\n",
      "founders                  0.458      0.229      0.382        380       5756\n",
      "genre                     0.403      0.182      0.324        170       5546\n",
      "has_sibling               0.543      0.126      0.327        499       5875\n",
      "has_spouse                0.678      0.231      0.489        594       5970\n",
      "is_a                      0.515      0.310      0.455        497       5873\n",
      "nationality               0.214      0.100      0.174        301       5677\n",
      "parents                   0.604      0.439      0.561        312       5688\n",
      "place_of_birth            0.415      0.189      0.335        233       5609\n",
      "place_of_death            0.062      0.019      0.043        159       5535\n",
      "profession                0.538      0.316      0.472        247       5623\n",
      "worked_at                 0.450      0.202      0.361        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.507      0.265      0.416       9248      95264\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    fourgram_pos_tag_results = rel_ext.experiment(\n",
    "        splits,\n",
    "        train_split='train',\n",
    "        test_split='dev',\n",
    "        featurizers=[middle_4gram_pos_tag_featurizer],\n",
    "        model_factory=lambda: SVC(kernel=\"linear\"),\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.837      0.303      0.619        340       5716\n",
      "author                    0.744      0.303      0.576        509       5885\n",
      "capital                   0.542      0.137      0.340         95       5471\n",
      "contains                  0.808      0.544      0.737       3904       9280\n",
      "film_performance          0.822      0.427      0.693        766       6142\n",
      "founders                  0.727      0.084      0.288        380       5756\n",
      "genre                     1.000      0.029      0.132        170       5546\n",
      "has_sibling               0.732      0.120      0.363        499       5875\n",
      "has_spouse                0.801      0.190      0.488        594       5970\n",
      "is_a                      0.805      0.125      0.385        497       5873\n",
      "nationality               0.692      0.060      0.222        301       5677\n",
      "parents                   0.689      0.292      0.542        312       5688\n",
      "place_of_birth            0.667      0.112      0.334        233       5609\n",
      "place_of_death            0.000      0.000      0.000        159       5535\n",
      "profession                0.796      0.158      0.440        247       5623\n",
      "worked_at                 0.364      0.017      0.070        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.689      0.181      0.389       9248      95264\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    threegram_pos_tag_results = rel_ext.experiment(\n",
    "        splits,\n",
    "        train_split='train',\n",
    "        test_split='dev',\n",
    "        featurizers=[middle_3gram_pos_tag_featurizer],\n",
    "        model_factory=lambda: SVC(kernel=\"rbf\"),\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.832      0.306      0.619        340       5716\n",
      "author                    0.741      0.287      0.563        509       5885\n",
      "capital                   0.545      0.126      0.328         95       5471\n",
      "contains                  0.812      0.524      0.731       3904       9280\n",
      "film_performance          0.811      0.403      0.675        766       6142\n",
      "founders                  0.667      0.105      0.323        380       5756\n",
      "genre                     1.000      0.029      0.132        170       5546\n",
      "has_sibling               0.711      0.108      0.336        499       5875\n",
      "has_spouse                0.757      0.189      0.472        594       5970\n",
      "is_a                      0.769      0.141      0.407        497       5873\n",
      "nationality               0.640      0.053      0.200        301       5677\n",
      "parents                   0.714      0.272      0.539        312       5688\n",
      "place_of_birth            0.727      0.103      0.329        233       5609\n",
      "place_of_death            0.000      0.000      0.000        159       5535\n",
      "profession                0.750      0.158      0.429        247       5623\n",
      "worked_at                 0.333      0.012      0.054        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.676      0.176      0.383       9248      95264\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    fourgram_pos_tag_results = rel_ext.experiment(\n",
    "        splits,\n",
    "        train_split='train',\n",
    "        test_split='dev',\n",
    "        featurizers=[middle_4gram_pos_tag_featurizer],\n",
    "        model_factory=lambda: SVC(kernel=\"rbf\"),\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Featurizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.843      0.426      0.705        340       5716\n",
      "author                    0.855      0.627      0.797        509       5885\n",
      "capital                   0.580      0.305      0.492         95       5471\n",
      "contains                  0.813      0.679      0.782       3904       9280\n",
      "film_performance          0.797      0.672      0.769        766       6142\n",
      "founders                  0.752      0.455      0.665        380       5756\n",
      "genre                     0.602      0.329      0.517        170       5546\n",
      "has_sibling               0.800      0.281      0.584        499       5875\n",
      "has_spouse                0.833      0.354      0.655        594       5970\n",
      "is_a                      0.694      0.292      0.544        497       5873\n",
      "nationality               0.556      0.262      0.455        301       5677\n",
      "parents                   0.828      0.554      0.753        312       5688\n",
      "place_of_birth            0.615      0.253      0.478        233       5609\n",
      "place_of_death            0.446      0.182      0.346        159       5535\n",
      "profession                0.653      0.267      0.507        247       5623\n",
      "worked_at                 0.667      0.331      0.554        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.708      0.392      0.600       9248      95264\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    dir_synset_results = rel_ext.experiment(\n",
    "        splits,\n",
    "        train_split='train',\n",
    "        test_split='dev',\n",
    "        featurizers=[directional_bag_of_words_featurizer, synset_featurizer],\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.798      0.418      0.675        340       5716\n",
      "author                    0.856      0.652      0.805        509       5885\n",
      "capital                   0.574      0.284      0.477         95       5471\n",
      "contains                  0.764      0.756      0.762       3904       9280\n",
      "film_performance          0.802      0.691      0.777        766       6142\n",
      "founders                  0.757      0.450      0.666        380       5756\n",
      "genre                     0.667      0.376      0.578        170       5546\n",
      "has_sibling               0.824      0.281      0.594        499       5875\n",
      "has_spouse                0.841      0.374      0.673        594       5970\n",
      "is_a                      0.708      0.360      0.593        497       5873\n",
      "nationality               0.568      0.319      0.491        301       5677\n",
      "parents                   0.833      0.577      0.765        312       5688\n",
      "place_of_birth            0.610      0.275      0.490        233       5609\n",
      "place_of_death            0.460      0.145      0.320        159       5535\n",
      "profession                0.722      0.368      0.606        247       5623\n",
      "worked_at                 0.656      0.339      0.553        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.715      0.417      0.614       9248      95264\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    dir_synset_bigram_results = rel_ext.experiment(\n",
    "        splits,\n",
    "        train_split='train',\n",
    "        test_split='dev',\n",
    "        featurizers=[directional_bag_of_words_featurizer, synset_featurizer, middle_bigram_pos_tag_featurizer],\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.713      0.409      0.621        340       5716\n",
      "author                    0.746      0.682      0.732        509       5885\n",
      "capital                   0.493      0.347      0.455         95       5471\n",
      "contains                  0.726      0.750      0.730       3904       9280\n",
      "film_performance          0.737      0.732      0.736        766       6142\n",
      "founders                  0.660      0.489      0.617        380       5756\n",
      "genre                     0.553      0.518      0.546        170       5546\n",
      "has_sibling               0.656      0.253      0.497        499       5875\n",
      "has_spouse                0.732      0.372      0.613        594       5970\n",
      "is_a                      0.572      0.390      0.523        497       5873\n",
      "nationality               0.455      0.365      0.433        301       5677\n",
      "parents                   0.754      0.590      0.714        312       5688\n",
      "place_of_birth            0.420      0.270      0.378        233       5609\n",
      "place_of_death            0.307      0.170      0.264        159       5535\n",
      "profession                0.563      0.417      0.526        247       5623\n",
      "worked_at                 0.540      0.393      0.502        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.602      0.447      0.556       9248      95264\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    dir_synset_bigram_svm_results = rel_ext.experiment(\n",
    "        splits,\n",
    "        train_split='train',\n",
    "        test_split='dev',\n",
    "        featurizers=[directional_bag_of_words_featurizer, synset_featurizer, middle_bigram_pos_tag_featurizer],\n",
    "        model_factory=lambda: SVC(kernel=\"linear\"),\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.766      0.376      0.635        340       5716\n",
      "author                    0.792      0.605      0.746        509       5885\n",
      "capital                   0.585      0.326      0.505         95       5471\n",
      "contains                  0.817      0.633      0.772       3904       9280\n",
      "film_performance          0.770      0.628      0.736        766       6142\n",
      "founders                  0.743      0.403      0.635        380       5756\n",
      "genre                     0.581      0.318      0.498        170       5546\n",
      "has_sibling               0.826      0.277      0.591        499       5875\n",
      "has_spouse                0.832      0.350      0.652        594       5970\n",
      "is_a                      0.632      0.342      0.540        497       5873\n",
      "nationality               0.526      0.203      0.399        301       5677\n",
      "parents                   0.833      0.577      0.765        312       5688\n",
      "place_of_birth            0.600      0.219      0.445        233       5609\n",
      "place_of_death            0.377      0.126      0.270        159       5535\n",
      "profession                0.650      0.316      0.536        247       5623\n",
      "worked_at                 0.617      0.293      0.506        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.684      0.374      0.577       9248      95264\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    synset_bigram_results = rel_ext.experiment(\n",
    "        splits,\n",
    "        train_split='train',\n",
    "        test_split='dev',\n",
    "        featurizers=[synset_featurizer, middle_bigram_pos_tag_featurizer],\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.862      0.403      0.702        340       5716\n",
      "author                    0.832      0.635      0.784        509       5885\n",
      "capital                   0.758      0.263      0.551         95       5471\n",
      "contains                  0.846      0.681      0.807       3904       9280\n",
      "film_performance          0.867      0.680      0.822        766       6142\n",
      "founders                  0.794      0.416      0.672        380       5756\n",
      "genre                     0.789      0.329      0.617        170       5546\n",
      "has_sibling               0.865      0.257      0.587        499       5875\n",
      "has_spouse                0.884      0.370      0.692        594       5970\n",
      "is_a                      0.791      0.336      0.623        497       5873\n",
      "nationality               0.598      0.223      0.447        301       5677\n",
      "parents                   0.901      0.554      0.801        312       5688\n",
      "place_of_birth            0.681      0.266      0.519        233       5609\n",
      "place_of_death            0.511      0.151      0.346        159       5535\n",
      "profession                0.781      0.332      0.615        247       5623\n",
      "worked_at                 0.773      0.310      0.595        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.783      0.388      0.636       9248      95264\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    dir_bigram_results = rel_ext.experiment(\n",
    "        splits,\n",
    "        train_split='train',\n",
    "        test_split='dev',\n",
    "        featurizers=[directional_bag_of_words_featurizer, middle_bigram_pos_tag_featurizer],\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    dir_bigram_results = rel_ext.experiment(\n",
    "        splits,\n",
    "        train_split='train',\n",
    "        test_split='dev',\n",
    "        featurizers=[directional_bag_of_words_featurizer, middle_bigram_pos_tag_featurizer],\n",
    "        model_factory=lambda: RandomForestClassifier(),\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.838      0.412      0.694        340       5716\n",
      "author                    0.851      0.629      0.795        509       5885\n",
      "capital                   0.600      0.221      0.447         95       5471\n",
      "contains                  0.850      0.592      0.782       3904       9280\n",
      "film_performance          0.842      0.572      0.770        766       6142\n",
      "founders                  0.873      0.379      0.692        380       5756\n",
      "genre                     0.638      0.218      0.460        170       5546\n",
      "has_sibling               0.844      0.283      0.604        499       5875\n",
      "has_spouse                0.865      0.379      0.688        594       5970\n",
      "is_a                      0.835      0.233      0.551        497       5873\n",
      "nationality               0.732      0.199      0.477        301       5677\n",
      "parents                   0.809      0.583      0.751        312       5688\n",
      "place_of_birth            0.770      0.202      0.493        233       5609\n",
      "place_of_death            0.556      0.094      0.281        159       5535\n",
      "profession                0.765      0.263      0.554        247       5623\n",
      "worked_at                 0.657      0.277      0.515        242       5618\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.770      0.346      0.597       9248      95264\n"
     ]
    }
   ],
   "source": [
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    dir_synset_bigram_gb_results = rel_ext.experiment(\n",
    "        splits,\n",
    "        train_split='train',\n",
    "        test_split='dev',\n",
    "        featurizers=[directional_bag_of_words_featurizer, synset_featurizer, middle_bigram_pos_tag_featurizer],\n",
    "        model_factory=lambda: GradientBoostingClassifier(),\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.881      0.456      0.742        777      12519\n",
      "author                    0.856      0.613      0.793       1170      12912\n",
      "capital                   0.775      0.267      0.562        232      11974\n",
      "contains                  0.845      0.644      0.795       9165      20907\n",
      "film_performance          0.861      0.693      0.821       1741      13483\n",
      "founders                  0.792      0.419      0.672        853      12595\n",
      "genre                     0.696      0.328      0.569        357      12099\n",
      "has_sibling               0.903      0.280      0.624       1159      12901\n",
      "has_spouse                0.898      0.391      0.713       1336      13078\n",
      "is_a                      0.723      0.328      0.582       1143      12885\n",
      "nationality               0.620      0.287      0.503        683      12425\n",
      "parents                   0.866      0.551      0.777        690      12432\n",
      "place_of_birth            0.798      0.278      0.581        482      12224\n",
      "place_of_death            0.612      0.111      0.321        371      12113\n",
      "profession                0.728      0.345      0.596        560      12302\n",
      "worked_at                 0.801      0.335      0.627        504      12246\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.791      0.395      0.642      21223     209095\n"
     ]
    }
   ],
   "source": [
    "# Enter your system description in this cell.\n",
    "\n",
    "# (1) System Description\n",
    "\"\"\"\n",
    "My system is pretty simple, consisting of both the directional\n",
    "bag of words featurizer, and the middle bigram pos tag featurizer\n",
    "used in the examples above, and it uses the default LogisticRegression\n",
    "model for the model_factory argument. In hopes of possibly outperforming\n",
    "on the hidden test set and avoiding overfitting, I adjusted the \n",
    "training/validation sets used here to be 55% and 44% of the data respectively\n",
    "instead of the default 79% and 20% splits.\n",
    "\n",
    "I experimented above with various other sklearn models, attempted 3-gram and 4-gram\n",
    "pos tag featurizers, and different combinations of featurizers and ultimately came\n",
    "to the LogisticRegression model performing more or less the same as any other,\n",
    "and that my chosen pair of featurizers did better than any single featurizer or\n",
    "combination of featurizers tested.\n",
    "\"\"\"\n",
    "\n",
    "# (2) Original System code\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    splits = dataset.build_splits(\n",
    "        split_names=['tiny', 'train', 'dev'],\n",
    "        split_fracs=[0.01, 0.55, 0.44],\n",
    "        seed=1)\n",
    "        \n",
    "    dir_bigram_lr_results = rel_ext.experiment(\n",
    "        splits,\n",
    "        train_split='train',\n",
    "        test_split='dev',\n",
    "        featurizers=[directional_bag_of_words_featurizer, middle_bigram_pos_tag_featurizer],\n",
    "        model_factory=lambda: LogisticRegression(fit_intercept=True, solver='liblinear'),\n",
    "        verbose=True)\n",
    "\n",
    "# (3) Score\n",
    "# My peak score was: 0.642\n",
    "\n",
    "# Please do not remove this comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bake-off [1 point]\n",
    "\n",
    "For the bake-off, we will release a test set. The announcement will go out on the discussion forum. You will evaluate your custom model from the previous question on these new datasets using the function `rel_ext.bake_off_experiment`. Rules:\n",
    "\n",
    "1. Only one evaluation is permitted.\n",
    "1. No additional system tuning is permitted once the bake-off has started.\n",
    "\n",
    "The cells below this one constitute your bake-off entry.\n",
    "\n",
    "People who enter will receive the additional homework point, and people whose systems achieve the top score will receive an additional 0.5 points. We will test the top-performing systems ourselves, and only systems for which we can reproduce the reported results will win the extra 0.5 points.\n",
    "\n",
    "Late entries will be accepted, but they cannot earn the extra 0.5 points. Similarly, you cannot win the bake-off unless your homework is submitted on time.\n",
    "\n",
    "The announcement will include the details on where to submit your entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support       size\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "adjoins                   0.886      0.463      0.750        438       7122\n",
      "author                    0.828      0.626      0.778        645       7329\n",
      "capital                   0.740      0.322      0.587        115       6799\n",
      "contains                  0.794      0.663      0.764       3808      10492\n",
      "film_performance          0.829      0.675      0.792       1011       7695\n",
      "founders                  0.779      0.412      0.661        444       7128\n",
      "genre                     0.647      0.351      0.554        188       6872\n",
      "has_sibling               0.894      0.234      0.572        717       7401\n",
      "has_spouse                0.869      0.358      0.676        780       7464\n",
      "is_a                      0.727      0.283      0.553        611       7295\n",
      "nationality               0.616      0.264      0.486        383       7067\n",
      "parents                   0.943      0.539      0.820        427       7111\n",
      "place_of_birth            0.757      0.268      0.555        291       6975\n",
      "place_of_death            0.540      0.135      0.338        200       6884\n",
      "profession                0.728      0.268      0.542        310       6994\n",
      "worked_at                 0.807      0.297      0.601        323       7007\n",
      "------------------    ---------  ---------  ---------  ---------  ---------\n",
      "macro-average             0.774      0.385      0.627      10691     117635\n"
     ]
    }
   ],
   "source": [
    "# Enter your bake-off assessment code in this cell. \n",
    "# Please do not remove this comment.\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    # Please enter your code in the scope of the above conditional.\n",
    "    ##### YOUR CODE HERE\n",
    "    splits = dataset.build_splits(\n",
    "        split_names=['tiny', 'train', 'dev'],\n",
    "        split_fracs=[0.01, 0.55, 0.44],\n",
    "        seed=1)\n",
    "        \n",
    "    bakeoff_results = rel_ext.experiment(\n",
    "        splits,\n",
    "        train_split='train',\n",
    "        test_split='dev',\n",
    "        featurizers=[directional_bag_of_words_featurizer, middle_bigram_pos_tag_featurizer],\n",
    "        model_factory=lambda: LogisticRegression(fit_intercept=True, solver='liblinear'),\n",
    "        verbose=False)\n",
    "\n",
    "    rel_ext_data_home_test = os.path.join(rel_ext_data_home, 'bakeoff-rel_ext-test-data')\n",
    "    rel_ext.bake_off_experiment(bakeoff_results, rel_ext_data_home_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On an otherwise blank line in this cell, please enter\n",
    "# your macro-average f-score (an F_0.5 score) as reported \n",
    "# by the code above. Please enter only a number between \n",
    "# 0 and 1 inclusive. Please do not remove this comment.\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    # Please enter your score in the scope of the above conditional.\n",
    "    ##### YOUR CODE HERE\n",
    "    0.627\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
